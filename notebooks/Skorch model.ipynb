{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import skorch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "from scipy.io import arff\n",
    "\n",
    "%matplotlib inline\n",
    "jtplot.style('gruvboxd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd().replace('Notebooks', 'data'), 'ct-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load dataset\n",
    "data = arff.loadarff(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reprocucibility\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "torch.manual_seed(2022)\n",
    "np.random.default_rng(2022)\n",
    "random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53500,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>value0</th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "      <th>value3</th>\n",
       "      <th>value4</th>\n",
       "      <th>value5</th>\n",
       "      <th>value6</th>\n",
       "      <th>value7</th>\n",
       "      <th>value8</th>\n",
       "      <th>...</th>\n",
       "      <th>value375</th>\n",
       "      <th>value376</th>\n",
       "      <th>value377</th>\n",
       "      <th>value378</th>\n",
       "      <th>value379</th>\n",
       "      <th>value380</th>\n",
       "      <th>value381</th>\n",
       "      <th>value382</th>\n",
       "      <th>value383</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "      <td>53500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47.075701</td>\n",
       "      <td>0.059627</td>\n",
       "      <td>0.071558</td>\n",
       "      <td>0.145819</td>\n",
       "      <td>0.218728</td>\n",
       "      <td>0.274762</td>\n",
       "      <td>0.276189</td>\n",
       "      <td>0.204531</td>\n",
       "      <td>0.062281</td>\n",
       "      <td>-0.042025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029404</td>\n",
       "      <td>0.182913</td>\n",
       "      <td>0.320112</td>\n",
       "      <td>0.359373</td>\n",
       "      <td>0.342889</td>\n",
       "      <td>0.266091</td>\n",
       "      <td>0.083049</td>\n",
       "      <td>-0.031146</td>\n",
       "      <td>-0.154524</td>\n",
       "      <td>47.028039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27.414240</td>\n",
       "      <td>0.174243</td>\n",
       "      <td>0.196921</td>\n",
       "      <td>0.300270</td>\n",
       "      <td>0.359163</td>\n",
       "      <td>0.378862</td>\n",
       "      <td>0.369605</td>\n",
       "      <td>0.351294</td>\n",
       "      <td>0.292232</td>\n",
       "      <td>0.268391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085817</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.463517</td>\n",
       "      <td>0.478188</td>\n",
       "      <td>0.471811</td>\n",
       "      <td>0.437633</td>\n",
       "      <td>0.279734</td>\n",
       "      <td>0.098738</td>\n",
       "      <td>0.122491</td>\n",
       "      <td>22.347042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>1.738733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>29.891607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>43.987893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.684477</td>\n",
       "      <td>0.662382</td>\n",
       "      <td>0.441412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996286</td>\n",
       "      <td>0.999677</td>\n",
       "      <td>0.999560</td>\n",
       "      <td>0.949478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.735059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>0.996468</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>0.996839</td>\n",
       "      <td>0.942851</td>\n",
       "      <td>97.489115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          patientId        value0        value1        value2        value3  \\\n",
       "count  53500.000000  53500.000000  53500.000000  53500.000000  53500.000000   \n",
       "mean      47.075701      0.059627      0.071558      0.145819      0.218728   \n",
       "std       27.414240      0.174243      0.196921      0.300270      0.359163   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       23.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%       46.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       70.000000      0.000000      0.000000      0.000000      0.446429   \n",
       "max       96.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             value4        value5        value6        value7        value8  \\\n",
       "count  53500.000000  53500.000000  53500.000000  53500.000000  53500.000000   \n",
       "mean       0.274762      0.276189      0.204531      0.062281     -0.042025   \n",
       "std        0.378862      0.369605      0.351294      0.292232      0.268391   \n",
       "min        0.000000     -0.250000     -0.250000     -0.250000     -0.250000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000     -0.250000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.684477      0.662382      0.441412      0.000000      0.000000   \n",
       "max        0.998790      0.996468      0.999334      1.000000      1.000000   \n",
       "\n",
       "       ...      value375      value376      value377      value378  \\\n",
       "count  ...  53500.000000  53500.000000  53500.000000  53500.000000   \n",
       "mean   ...     -0.029404      0.182913      0.320112      0.359373   \n",
       "std    ...      0.085817      0.383333      0.463517      0.478188   \n",
       "min    ...     -0.250000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.996286      0.999677   \n",
       "max    ...      0.961279      1.000000      1.000000      1.000000   \n",
       "\n",
       "           value379      value380      value381      value382      value383  \\\n",
       "count  53500.000000  53500.000000  53500.000000  53500.000000  53500.000000   \n",
       "mean       0.342889      0.266091      0.083049     -0.031146     -0.154524   \n",
       "std        0.471811      0.437633      0.279734      0.098738      0.122491   \n",
       "min        0.000000      0.000000     -0.250000     -0.250000     -0.250000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000     -0.250000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000     -0.250000   \n",
       "75%        0.999560      0.949478      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      0.999857      0.996839      0.942851   \n",
       "\n",
       "          reference  \n",
       "count  53500.000000  \n",
       "mean      47.028039  \n",
       "std       22.347042  \n",
       "min        1.738733  \n",
       "25%       29.891607  \n",
       "50%       43.987893  \n",
       "75%       63.735059  \n",
       "max       97.489115  \n",
       "\n",
       "[8 rows x 386 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>value0</th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "      <th>value3</th>\n",
       "      <th>value4</th>\n",
       "      <th>value5</th>\n",
       "      <th>value6</th>\n",
       "      <th>value7</th>\n",
       "      <th>value8</th>\n",
       "      <th>...</th>\n",
       "      <th>value375</th>\n",
       "      <th>value376</th>\n",
       "      <th>value377</th>\n",
       "      <th>value378</th>\n",
       "      <th>value379</th>\n",
       "      <th>value380</th>\n",
       "      <th>value381</th>\n",
       "      <th>value382</th>\n",
       "      <th>value383</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.980381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>21.803851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.977008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>21.745726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.977008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>21.687600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.977008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>21.629474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.976833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>21.571348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patientId  value0  value1  value2  value3  value4  value5  value6  value7  \\\n",
       "0        0.0     0.0     0.0     0.0     0.0     0.0     0.0   -0.25   -0.25   \n",
       "1        0.0     0.0     0.0     0.0     0.0     0.0     0.0   -0.25   -0.25   \n",
       "2        0.0     0.0     0.0     0.0     0.0     0.0     0.0   -0.25   -0.25   \n",
       "3        0.0     0.0     0.0     0.0     0.0     0.0     0.0   -0.25   -0.25   \n",
       "4        0.0     0.0     0.0     0.0     0.0     0.0     0.0   -0.25   -0.25   \n",
       "\n",
       "   value8  ...  value375  value376  value377  value378  value379  value380  \\\n",
       "0   -0.25  ...     -0.25  0.980381       0.0       0.0       0.0       0.0   \n",
       "1   -0.25  ...     -0.25  0.977008       0.0       0.0       0.0       0.0   \n",
       "2   -0.25  ...     -0.25  0.977008       0.0       0.0       0.0       0.0   \n",
       "3   -0.25  ...     -0.25  0.977008       0.0       0.0       0.0       0.0   \n",
       "4   -0.25  ...     -0.25  0.976833       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   value381  value382  value383  reference  \n",
       "0       0.0     -0.25     -0.25  21.803851  \n",
       "1       0.0     -0.25     -0.25  21.745726  \n",
       "2       0.0     -0.25     -0.25  21.687600  \n",
       "3       0.0     -0.25     -0.25  21.629474  \n",
       "4       0.0     -0.25     -0.25  21.571348  \n",
       "\n",
       "[5 rows x 386 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53500, 386)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patientId    float64\n",
       "value0       float64\n",
       "value1       float64\n",
       "value2       float64\n",
       "value3       float64\n",
       "              ...   \n",
       "value380     float64\n",
       "value381     float64\n",
       "value382     float64\n",
       "value383     float64\n",
       "reference    float64\n",
       "Length: 386, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value311     3\n",
       "value68      2\n",
       "value59      1\n",
       "value168     3\n",
       "value99      4\n",
       "value262     6\n",
       "value270    27\n",
       "value209    13\n",
       "value367     2\n",
       "value48      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Possibly categorical features\n",
    "cat_features = new_data.nunique()[new_data.nunique() < 50].index\n",
    "new_data.nunique()[new_data.nunique() < 50].sample(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Features and targets\n",
    "X, y = new_data.drop(labels = ['patientId', 'reference'], axis = 1), new_data.iloc[:, -1]\n",
    "y = y.values.reshape(len(X), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature diagnostics (Feature value37)\n",
      "\t0.0 has a count(s) of  0.8284\n",
      "\t-0.25 has a count(s) of  0.1710\n",
      "\t0.091011 has a count(s) of  0.0001\n",
      "\t0.61636 has a count(s) of  0.0000\n",
      "\t0.340495 has a count(s) of  0.0000\n",
      "\t0.54983 has a count(s) of  0.0000\n",
      "\t0.484688 has a count(s) of  0.0000\n",
      "\t0.536246 has a count(s) of  0.0000\n",
      "\t0.502759 has a count(s) of  0.0000\n",
      "\t0.581729 has a count(s) of  0.0000\n",
      "\t0.141197 has a count(s) of  0.0000\n",
      "\t0.668654 has a count(s) of  0.0000\n",
      "\t0.54172 has a count(s) of  0.0000\n",
      "\t0.106509 has a count(s) of  0.0000\n",
      "\t0.408232 has a count(s) of  0.0000\n",
      "\t0.1861 has a count(s) of  0.0000\n",
      "\t0.286726 has a count(s) of  0.0000\n",
      "\t0.231801 has a count(s) of  0.0000\n",
      "\t0.168574 has a count(s) of  0.0000\n",
      "\t0.684122 has a count(s) of  0.0000\n",
      "\t0.824634 has a count(s) of  0.0000\n",
      "\t0.566096 has a count(s) of  0.0000\n",
      "\t0.111724 has a count(s) of  0.0000\n",
      "\t0.335751 has a count(s) of  0.0000\n",
      "\t0.635486 has a count(s) of  0.0000\n",
      "\t0.38756 has a count(s) of  0.0000\n",
      "\t0.721604 has a count(s) of  0.0000\n",
      "\t0.673247 has a count(s) of  0.0000\n",
      "\t0.077143 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value38)\n",
      "\t0.0 has a count(s) of  0.5067\n",
      "\t-0.25 has a count(s) of  0.4933\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value39)\n",
      "\t-0.25 has a count(s) of  0.7986\n",
      "\t0.0 has a count(s) of  0.2014\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value48)\n",
      "\t-0.25 has a count(s) of  0.8694\n",
      "\t0.0 has a count(s) of  0.1306\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value49)\n",
      "\t-0.25 has a count(s) of  0.9811\n",
      "\t0.0 has a count(s) of  0.0189\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value58)\n",
      "\t-0.25 has a count(s) of  0.9828\n",
      "\t0.0 has a count(s) of  0.0170\n",
      "\t0.561798 has a count(s) of  0.0000\n",
      "\t0.536673 has a count(s) of  0.0000\n",
      "\t0.277008 has a count(s) of  0.0000\n",
      "\t0.673854 has a count(s) of  0.0000\n",
      "\t0.713436 has a count(s) of  0.0000\n",
      "\t0.481928 has a count(s) of  0.0000\n",
      "\t0.613497 has a count(s) of  0.0000\n",
      "\t0.633914 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value59)\n",
      "\t-0.25 has a count(s) of  1.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value68)\n",
      "\t-0.25 has a count(s) of  0.9828\n",
      "\t0.0 has a count(s) of  0.0172\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value69)\n",
      "\t-0.25 has a count(s) of  1.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value78)\n",
      "\t-0.25 has a count(s) of  0.8694\n",
      "\t0.0 has a count(s) of  0.1306\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value79)\n",
      "\t-0.25 has a count(s) of  0.9811\n",
      "\t0.0 has a count(s) of  0.0189\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value88)\n",
      "\t-0.25 has a count(s) of  0.5012\n",
      "\t0.0 has a count(s) of  0.4988\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value89)\n",
      "\t-0.25 has a count(s) of  0.8044\n",
      "\t0.0 has a count(s) of  0.1956\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value99)\n",
      "\t0.0 has a count(s) of  0.8837\n",
      "\t-0.25 has a count(s) of  0.1162\n",
      "\t0.15817 has a count(s) of  0.0000\n",
      "\t0.157963 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value159)\n",
      "\t-0.25 has a count(s) of  0.8036\n",
      "\t0.0 has a count(s) of  0.1954\n",
      "\t0.971888 has a count(s) of  0.0001\n",
      "\t0.960317 has a count(s) of  0.0001\n",
      "\t0.98374 has a count(s) of  0.0001\n",
      "\t1.0 has a count(s) of  0.0001\n",
      "\t0.991803 has a count(s) of  0.0001\n",
      "\t0.741681 has a count(s) of  0.0000\n",
      "\t0.97561 has a count(s) of  0.0000\n",
      "\t0.99384 has a count(s) of  0.0000\n",
      "\t0.983673 has a count(s) of  0.0000\n",
      "\t0.288783 has a count(s) of  0.0000\n",
      "\t0.44898 has a count(s) of  0.0000\n",
      "\t0.987179 has a count(s) of  0.0000\n",
      "\t0.930769 has a count(s) of  0.0000\n",
      "\t0.968 has a count(s) of  0.0000\n",
      "\t0.978964 has a count(s) of  0.0000\n",
      "\t0.99177 has a count(s) of  0.0000\n",
      "\t0.997253 has a count(s) of  0.0000\n",
      "\t0.96 has a count(s) of  0.0000\n",
      "\t0.995876 has a count(s) of  0.0000\n",
      "\t0.975806 has a count(s) of  0.0000\n",
      "\t0.99835 has a count(s) of  0.0000\n",
      "\t0.857651 has a count(s) of  0.0000\n",
      "\t0.833333 has a count(s) of  0.0000\n",
      "\t0.710372 has a count(s) of  0.0000\n",
      "\t0.28673 has a count(s) of  0.0000\n",
      "\t0.566303 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value168)\n",
      "\t-0.25 has a count(s) of  0.8704\n",
      "\t0.0 has a count(s) of  0.1296\n",
      "\t0.934375 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value169)\n",
      "\t-0.25 has a count(s) of  0.9829\n",
      "\t0.0 has a count(s) of  0.0171\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value178)\n",
      "\t-0.25 has a count(s) of  0.9842\n",
      "\t0.0 has a count(s) of  0.0158\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value179)\n",
      "\t-0.25 has a count(s) of  1.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value188)\n",
      "\t-0.25 has a count(s) of  0.9842\n",
      "\t0.0 has a count(s) of  0.0158\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value189)\n",
      "\t-0.25 has a count(s) of  1.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value198)\n",
      "\t-0.25 has a count(s) of  0.8704\n",
      "\t0.0 has a count(s) of  0.1295\n",
      "\t0.694444 has a count(s) of  0.0000\n",
      "\t0.75188 has a count(s) of  0.0000\n",
      "\t0.666667 has a count(s) of  0.0000\n",
      "\t0.808943 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value199)\n",
      "\t-0.25 has a count(s) of  0.9829\n",
      "\t0.0 has a count(s) of  0.0171\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value209)\n",
      "\t-0.25 has a count(s) of  0.8086\n",
      "\t0.0 has a count(s) of  0.1911\n",
      "\t0.857651 has a count(s) of  0.0001\n",
      "\t0.942857 has a count(s) of  0.0001\n",
      "\t0.916667 has a count(s) of  0.0000\n",
      "\t0.296569 has a count(s) of  0.0000\n",
      "\t0.775641 has a count(s) of  0.0000\n",
      "\t0.806667 has a count(s) of  0.0000\n",
      "\t0.960317 has a count(s) of  0.0000\n",
      "\t0.864286 has a count(s) of  0.0000\n",
      "\t0.481113 has a count(s) of  0.0000\n",
      "\t0.703488 has a count(s) of  0.0000\n",
      "\t0.294404 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value247)\n",
      "\t-0.25 has a count(s) of  0.6192\n",
      "\t0.0 has a count(s) of  0.3807\n",
      "\t0.726122 has a count(s) of  0.0001\n",
      "\t0.701427 has a count(s) of  0.0000\n",
      "\t0.69183 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value254)\n",
      "\t0.0 has a count(s) of  0.9901\n",
      "\t-0.25 has a count(s) of  0.0095\n",
      "\t0.71623 has a count(s) of  0.0000\n",
      "\t0.469753 has a count(s) of  0.0000\n",
      "\t0.33874 has a count(s) of  0.0000\n",
      "\t0.336694 has a count(s) of  0.0000\n",
      "\t0.670276 has a count(s) of  0.0000\n",
      "\t0.506158 has a count(s) of  0.0000\n",
      "\t0.873817 has a count(s) of  0.0000\n",
      "\t0.499702 has a count(s) of  0.0000\n",
      "\t0.668696 has a count(s) of  0.0000\n",
      "\t0.340697 has a count(s) of  0.0000\n",
      "\t0.756501 has a count(s) of  0.0000\n",
      "\t0.493706 has a count(s) of  0.0000\n",
      "\t0.327241 has a count(s) of  0.0000\n",
      "\t0.339571 has a count(s) of  0.0000\n",
      "\t0.327141 has a count(s) of  0.0000\n",
      "\t0.331424 has a count(s) of  0.0000\n",
      "\t0.35492 has a count(s) of  0.0000\n",
      "\t0.354038 has a count(s) of  0.0000\n",
      "\t0.335287 has a count(s) of  0.0000\n",
      "\t0.668192 has a count(s) of  0.0000\n",
      "\t0.306365 has a count(s) of  0.0000\n",
      "\t0.470479 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value255)\n",
      "\t0.0 has a count(s) of  0.8787\n",
      "\t-0.25 has a count(s) of  0.1213\n",
      "\t0.470689 has a count(s) of  0.0000\n",
      "\t0.476204 has a count(s) of  0.0000\n",
      "\t0.477101 has a count(s) of  0.0000\n",
      "\t0.47086 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value262)\n",
      "\t0.0 has a count(s) of  0.9147\n",
      "\t-0.25 has a count(s) of  0.0852\n",
      "\t0.575599 has a count(s) of  0.0000\n",
      "\t0.315483 has a count(s) of  0.0000\n",
      "\t0.647879 has a count(s) of  0.0000\n",
      "\t0.311005 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value263)\n",
      "\t0.0 has a count(s) of  0.5836\n",
      "\t-0.25 has a count(s) of  0.4164\n",
      "\t0.813408 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value270)\n",
      "\t-0.25 has a count(s) of  0.8200\n",
      "\t0.0 has a count(s) of  0.1795\n",
      "\t0.782212 has a count(s) of  0.0000\n",
      "\t0.517817 has a count(s) of  0.0000\n",
      "\t0.728641 has a count(s) of  0.0000\n",
      "\t0.424704 has a count(s) of  0.0000\n",
      "\t0.69282 has a count(s) of  0.0000\n",
      "\t0.433312 has a count(s) of  0.0000\n",
      "\t0.354154 has a count(s) of  0.0000\n",
      "\t0.869312 has a count(s) of  0.0000\n",
      "\t0.406572 has a count(s) of  0.0000\n",
      "\t0.328375 has a count(s) of  0.0000\n",
      "\t0.601091 has a count(s) of  0.0000\n",
      "\t0.357031 has a count(s) of  0.0000\n",
      "\t0.615888 has a count(s) of  0.0000\n",
      "\t0.724255 has a count(s) of  0.0000\n",
      "\t0.681481 has a count(s) of  0.0000\n",
      "\t0.721757 has a count(s) of  0.0000\n",
      "\t0.674652 has a count(s) of  0.0000\n",
      "\t0.822213 has a count(s) of  0.0000\n",
      "\t0.837198 has a count(s) of  0.0000\n",
      "\t0.67189 has a count(s) of  0.0000\n",
      "\t0.608036 has a count(s) of  0.0000\n",
      "\t0.721398 has a count(s) of  0.0000\n",
      "\t0.517469 has a count(s) of  0.0000\n",
      "\t0.805081 has a count(s) of  0.0000\n",
      "\t0.725751 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value271)\n",
      "\t-0.25 has a count(s) of  0.9378\n",
      "\t0.0 has a count(s) of  0.0622\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value279)\n",
      "\t-0.25 has a count(s) of  1.0000\n",
      "\t0.0 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value286)\n",
      "\t-0.25 has a count(s) of  0.8200\n",
      "\t0.0 has a count(s) of  0.1796\n",
      "\t0.80422 has a count(s) of  0.0001\n",
      "\t0.691633 has a count(s) of  0.0000\n",
      "\t0.493878 has a count(s) of  0.0000\n",
      "\t0.828422 has a count(s) of  0.0000\n",
      "\t0.760817 has a count(s) of  0.0000\n",
      "\t0.530733 has a count(s) of  0.0000\n",
      "\t0.360932 has a count(s) of  0.0000\n",
      "\t0.495137 has a count(s) of  0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0.677379 has a count(s) of  0.0000\n",
      "\t0.516467 has a count(s) of  0.0000\n",
      "\t0.608466 has a count(s) of  0.0000\n",
      "\t0.721757 has a count(s) of  0.0000\n",
      "\t0.767868 has a count(s) of  0.0000\n",
      "\t0.719228 has a count(s) of  0.0000\n",
      "\t0.338098 has a count(s) of  0.0000\n",
      "\t0.3405 has a count(s) of  0.0000\n",
      "\t0.67286 has a count(s) of  0.0000\n",
      "\t0.55914 has a count(s) of  0.0000\n",
      "\t0.848795 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value287)\n",
      "\t-0.25 has a count(s) of  0.9378\n",
      "\t0.0 has a count(s) of  0.0622\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value294)\n",
      "\t0.0 has a count(s) of  0.9146\n",
      "\t-0.25 has a count(s) of  0.0852\n",
      "\t0.575599 has a count(s) of  0.0000\n",
      "\t0.683816 has a count(s) of  0.0000\n",
      "\t0.807535 has a count(s) of  0.0000\n",
      "\t0.577095 has a count(s) of  0.0000\n",
      "\t0.30795 has a count(s) of  0.0000\n",
      "\t0.643405 has a count(s) of  0.0000\n",
      "\t0.308636 has a count(s) of  0.0000\n",
      "\t0.666176 has a count(s) of  0.0000\n",
      "\t0.307159 has a count(s) of  0.0000\n",
      "\t0.404769 has a count(s) of  0.0000\n",
      "\t0.311005 has a count(s) of  0.0000\n",
      "\t0.473899 has a count(s) of  0.0000\n",
      "\t0.308714 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value295)\n",
      "\t0.0 has a count(s) of  0.5836\n",
      "\t-0.25 has a count(s) of  0.4164\n",
      "\t0.843799 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value302)\n",
      "\t0.0 has a count(s) of  0.9914\n",
      "\t-0.25 has a count(s) of  0.0079\n",
      "\t0.329468 has a count(s) of  0.0001\n",
      "\t0.494892 has a count(s) of  0.0000\n",
      "\t0.778037 has a count(s) of  0.0000\n",
      "\t0.531593 has a count(s) of  0.0000\n",
      "\t0.697216 has a count(s) of  0.0000\n",
      "\t0.855697 has a count(s) of  0.0000\n",
      "\t0.803582 has a count(s) of  0.0000\n",
      "\t0.808746 has a count(s) of  0.0000\n",
      "\t0.374797 has a count(s) of  0.0000\n",
      "\t0.375983 has a count(s) of  0.0000\n",
      "\t0.379424 has a count(s) of  0.0000\n",
      "\t0.549731 has a count(s) of  0.0000\n",
      "\t0.478416 has a count(s) of  0.0000\n",
      "\t0.595151 has a count(s) of  0.0000\n",
      "\t0.327134 has a count(s) of  0.0000\n",
      "\t0.693756 has a count(s) of  0.0000\n",
      "\t0.736065 has a count(s) of  0.0000\n",
      "\t0.527007 has a count(s) of  0.0000\n",
      "\t0.867219 has a count(s) of  0.0000\n",
      "\t0.306306 has a count(s) of  0.0000\n",
      "\t0.305728 has a count(s) of  0.0000\n",
      "\t0.752867 has a count(s) of  0.0000\n",
      "\t0.332566 has a count(s) of  0.0000\n",
      "\t0.318358 has a count(s) of  0.0000\n",
      "\t0.91605 has a count(s) of  0.0000\n",
      "\t0.794455 has a count(s) of  0.0000\n",
      "\t0.737002 has a count(s) of  0.0000\n",
      "\t0.73086 has a count(s) of  0.0000\n",
      "\t0.984343 has a count(s) of  0.0000\n",
      "\t0.897107 has a count(s) of  0.0000\n",
      "\t0.974049 has a count(s) of  0.0000\n",
      "\t0.506471 has a count(s) of  0.0000\n",
      "\t0.337695 has a count(s) of  0.0000\n",
      "\t0.315727 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value303)\n",
      "\t0.0 has a count(s) of  0.8805\n",
      "\t-0.25 has a count(s) of  0.1191\n",
      "\t0.918037 has a count(s) of  0.0000\n",
      "\t0.501617 has a count(s) of  0.0000\n",
      "\t0.944805 has a count(s) of  0.0000\n",
      "\t0.920519 has a count(s) of  0.0000\n",
      "\t0.85871 has a count(s) of  0.0000\n",
      "\t0.927276 has a count(s) of  0.0000\n",
      "\t0.886636 has a count(s) of  0.0000\n",
      "\t0.672915 has a count(s) of  0.0000\n",
      "\t0.932983 has a count(s) of  0.0000\n",
      "\t0.526479 has a count(s) of  0.0000\n",
      "\t0.90974 has a count(s) of  0.0000\n",
      "\t0.975957 has a count(s) of  0.0000\n",
      "\t0.939848 has a count(s) of  0.0000\n",
      "\t0.97557 has a count(s) of  0.0000\n",
      "\t0.989172 has a count(s) of  0.0000\n",
      "\t0.951393 has a count(s) of  0.0000\n",
      "\t0.963262 has a count(s) of  0.0000\n",
      "\t0.978572 has a count(s) of  0.0000\n",
      "\t0.990522 has a count(s) of  0.0000\n",
      "\t0.487108 has a count(s) of  0.0000\n",
      "\t0.482662 has a count(s) of  0.0000\n",
      "\t0.534747 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value311)\n",
      "\t-0.25 has a count(s) of  0.6057\n",
      "\t0.0 has a count(s) of  0.3943\n",
      "\t0.670476 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value319)\n",
      "\t-0.25 has a count(s) of  0.6057\n",
      "\t0.0 has a count(s) of  0.3937\n",
      "\t0.818684 has a count(s) of  0.0001\n",
      "\t0.668238 has a count(s) of  0.0001\n",
      "\t0.785888 has a count(s) of  0.0000\n",
      "\t0.949171 has a count(s) of  0.0000\n",
      "\t0.960573 has a count(s) of  0.0000\n",
      "\t0.593791 has a count(s) of  0.0000\n",
      "\t0.596593 has a count(s) of  0.0000\n",
      "\t0.708985 has a count(s) of  0.0000\n",
      "\t0.697397 has a count(s) of  0.0000\n",
      "\t0.829229 has a count(s) of  0.0000\n",
      "\t0.763807 has a count(s) of  0.0000\n",
      "\t0.909836 has a count(s) of  0.0000\n",
      "\t0.921786 has a count(s) of  0.0000\n",
      "\t0.965114 has a count(s) of  0.0000\n",
      "\t0.943777 has a count(s) of  0.0000\n",
      "\t0.917702 has a count(s) of  0.0000\n",
      "\t0.902738 has a count(s) of  0.0000\n",
      "\t0.957378 has a count(s) of  0.0000\n",
      "\t0.622375 has a count(s) of  0.0000\n",
      "\t0.829108 has a count(s) of  0.0000\n",
      "\t0.761747 has a count(s) of  0.0000\n",
      "\t0.724499 has a count(s) of  0.0000\n",
      "\t0.890346 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value335)\n",
      "\t0.0 has a count(s) of  0.5756\n",
      "\t-0.25 has a count(s) of  0.4244\n",
      "\t0.515275 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value342)\n",
      "\t-0.25 has a count(s) of  0.8239\n",
      "\t0.0 has a count(s) of  0.1755\n",
      "\t0.771222 has a count(s) of  0.0000\n",
      "\t0.39507 has a count(s) of  0.0000\n",
      "\t0.394062 has a count(s) of  0.0000\n",
      "\t0.387435 has a count(s) of  0.0000\n",
      "\t0.612365 has a count(s) of  0.0000\n",
      "\t0.449535 has a count(s) of  0.0000\n",
      "\t0.573353 has a count(s) of  0.0000\n",
      "\t0.401617 has a count(s) of  0.0000\n",
      "\t0.668661 has a count(s) of  0.0000\n",
      "\t0.552632 has a count(s) of  0.0000\n",
      "\t0.566651 has a count(s) of  0.0000\n",
      "\t0.401091 has a count(s) of  0.0000\n",
      "\t0.813953 has a count(s) of  0.0000\n",
      "\t0.394273 has a count(s) of  0.0000\n",
      "\t0.723833 has a count(s) of  0.0000\n",
      "\t0.421559 has a count(s) of  0.0000\n",
      "\t0.376162 has a count(s) of  0.0000\n",
      "\t0.370805 has a count(s) of  0.0000\n",
      "\t0.433901 has a count(s) of  0.0000\n",
      "\t0.443257 has a count(s) of  0.0000\n",
      "\t0.705497 has a count(s) of  0.0000\n",
      "\t0.707203 has a count(s) of  0.0000\n",
      "\t0.658744 has a count(s) of  0.0000\n",
      "\t0.705413 has a count(s) of  0.0000\n",
      "\t0.58799 has a count(s) of  0.0000\n",
      "\t0.320302 has a count(s) of  0.0000\n",
      "\t0.31889 has a count(s) of  0.0000\n",
      "\t0.483082 has a count(s) of  0.0000\n",
      "\t0.315059 has a count(s) of  0.0000\n",
      "\t0.314345 has a count(s) of  0.0000\n",
      "\t0.835528 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value343)\n",
      "\t-0.25 has a count(s) of  0.9431\n",
      "\t0.0 has a count(s) of  0.0569\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value351)\n",
      "\t-0.25 has a count(s) of  1.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value359)\n",
      "\t-0.25 has a count(s) of  0.9431\n",
      "\t0.0 has a count(s) of  0.0569\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value367)\n",
      "\t0.0 has a count(s) of  0.5756\n",
      "\t-0.25 has a count(s) of  0.4244\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Feature diagnostics (Feature value383)\n",
      "\t-0.25 has a count(s) of  0.6192\n",
      "\t0.0 has a count(s) of  0.3804\n",
      "\t0.724499 has a count(s) of  0.0000\n",
      "\t0.649937 has a count(s) of  0.0000\n",
      "\t0.396201 has a count(s) of  0.0000\n",
      "\t0.563964 has a count(s) of  0.0000\n",
      "\t0.880152 has a count(s) of  0.0000\n",
      "\t0.374024 has a count(s) of  0.0000\n",
      "\t0.571206 has a count(s) of  0.0000\n",
      "\t0.385638 has a count(s) of  0.0000\n",
      "\t0.368231 has a count(s) of  0.0000\n",
      "\t0.549886 has a count(s) of  0.0000\n",
      "\t0.888412 has a count(s) of  0.0000\n",
      "\t0.709302 has a count(s) of  0.0000\n",
      "\t0.754049 has a count(s) of  0.0000\n",
      "\t0.942851 has a count(s) of  0.0000\n",
      "\t0.685022 has a count(s) of  0.0000\n",
      "\t0.738426 has a count(s) of  0.0000\n",
      "\t0.649626 has a count(s) of  0.0000\n",
      "\t0.399672 has a count(s) of  0.0000\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "### Drop invariant features\n",
    "to_drop = []\n",
    "\n",
    "for feature in cat_features:\n",
    "    counts = X[feature].value_counts(normalize = True)\n",
    "    print(f'Feature diagnostics (Feature {feature})')\n",
    "    \n",
    "    if counts.max() > 0.80:\n",
    "        to_drop.append(feature)\n",
    "    \n",
    "    for c in counts.index:\n",
    "        print(f'\\t{c} has a count(s) of {counts[c] : .4f}')\n",
    "    \n",
    "    print('+'*(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = X.drop(labels = to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert data to PyTorch tensors\n",
    "new_X, y = torch.from_numpy(new_X.values).to(torch.float32), torch.from_numpy(y).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.dtypes[new_data.dtypes != np.float64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['History',\n",
       " 'MIN_TORCH_VERSION',\n",
       " 'NeuralNet',\n",
       " 'NeuralNetBinaryClassifier',\n",
       " 'NeuralNetClassifier',\n",
       " 'NeuralNetRegressor',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'callbacks',\n",
       " 'classifier',\n",
       " 'dataset',\n",
       " 'exceptions',\n",
       " 'history',\n",
       " 'net',\n",
       " 'parse_version',\n",
       " 'pkg_resources',\n",
       " 'regressor',\n",
       " 'setter',\n",
       " 'sys',\n",
       " 'torch',\n",
       " 'torch_version',\n",
       " 'utils',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(skorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self, n_features, task = 'classif', n_classes = None):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.task = task\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        if self.task == 'classif':\n",
    "            assert self.n_classes is not None & type(self.n_classes) == int , 'Number of classes must be specified \\\n",
    "            if task is a Classification.'\n",
    "        \n",
    "        self.layer1 = nn.Linear(self.n_features, 2*self.n_features)\n",
    "        self.layer2 = nn.Linear(2*self.n_features, 4*self.n_features)\n",
    "        \n",
    "        if self.task != 'classif':\n",
    "            self.layer3 = nn.Linear(4*self.n_features, 1)\n",
    "        else:\n",
    "            self.layer3 = nn.Linear(4*self.n_features, self.n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = torch.softmax(self.layer3(x)) if self.task == 'classif' else self.layer3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet for regression tasks\n",
      "\n",
      "    Use this specifically if you have a standard regression task,\n",
      "    with input data X and target y. y must be 2d.\n",
      "\n",
      "    In addition to the parameters listed below, there are parameters\n",
      "    with specific prefixes that are handled separately. To illustrate\n",
      "    this, here is an example:\n",
      "\n",
      "    >>> net = NeuralNet(\n",
      "    ...    ...,\n",
      "    ...    optimizer=torch.optimizer.SGD,\n",
      "    ...    optimizer__momentum=0.95,\n",
      "    ...)\n",
      "\n",
      "    This way, when ``optimizer`` is initialized, :class:`.NeuralNet`\n",
      "    will take care of setting the ``momentum`` parameter to 0.95.\n",
      "\n",
      "    (Note that the double underscore notation in\n",
      "    ``optimizer__momentum`` means that the parameter ``momentum``\n",
      "    should be set on the object ``optimizer``. This is the same\n",
      "    semantic as used by sklearn.)\n",
      "\n",
      "    Furthermore, this allows to change those parameters later:\n",
      "\n",
      "    ``net.set_params(optimizer__momentum=0.99)``\n",
      "\n",
      "    This can be useful when you want to change certain parameters\n",
      "    using a callback, when using the net in an sklearn grid search,\n",
      "    etc.\n",
      "\n",
      "    By default an :class:`.EpochTimer`, :class:`.BatchScoring` (for\n",
      "    both training and validation datasets), and :class:`.PrintLog`\n",
      "    callbacks are installed for the user's convenience.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    module : torch module (class or instance)\n",
      "      A PyTorch :class:`~torch.nn.Module`. In general, the\n",
      "      uninstantiated class should be passed, although instantiated\n",
      "      modules will also work.\n",
      "\n",
      "    criterion : torch criterion (class, default=torch.nn.MSELoss)\n",
      "      Mean squared error loss.\n",
      "\n",
      "    optimizer : torch optim (class, default=torch.optim.SGD)\n",
      "      The uninitialized optimizer (update rule) used to optimize the\n",
      "      module\n",
      "\n",
      "    lr : float (default=0.01)\n",
      "      Learning rate passed to the optimizer. You may use ``lr`` instead\n",
      "      of using ``optimizer__lr``, which would result in the same outcome.\n",
      "\n",
      "    max_epochs : int (default=10)\n",
      "      The number of epochs to train for each ``fit`` call. Note that you\n",
      "      may keyboard-interrupt training at any time.\n",
      "\n",
      "    batch_size : int (default=128)\n",
      "      Mini-batch size. Use this instead of setting\n",
      "      ``iterator_train__batch_size`` and ``iterator_test__batch_size``,\n",
      "      which would result in the same outcome. If ``batch_size`` is -1,\n",
      "      a single batch with all the data will be used during training\n",
      "      and validation.\n",
      "\n",
      "    iterator_train : torch DataLoader\n",
      "      The default PyTorch :class:`~torch.utils.data.DataLoader` used for\n",
      "      training data.\n",
      "\n",
      "    iterator_valid : torch DataLoader\n",
      "      The default PyTorch :class:`~torch.utils.data.DataLoader` used for\n",
      "      validation and test data, i.e. during inference.\n",
      "\n",
      "    dataset : torch Dataset (default=skorch.dataset.Dataset)\n",
      "      The dataset is necessary for the incoming data to work with\n",
      "      pytorch's ``DataLoader``. It has to implement the ``__len__`` and\n",
      "      ``__getitem__`` methods. The provided dataset should be capable of\n",
      "      dealing with a lot of data types out of the box, so only change\n",
      "      this if your data is not supported. You should generally pass the\n",
      "      uninitialized ``Dataset`` class and define additional arguments to\n",
      "      X and y by prefixing them with ``dataset__``. It is also possible\n",
      "      to pass an initialzed ``Dataset``, in which case no additional\n",
      "      arguments may be passed.\n",
      "\n",
      "    train_split : None or callable (default=skorch.dataset.ValidSplit(5))\n",
      "      If None, there is no train/validation split. Else, train_split\n",
      "      should be a function or callable that is called with X and y\n",
      "      data and should return the tuple ``dataset_train, dataset_valid``.\n",
      "      The validation data may be None.\n",
      "\n",
      "    callbacks : None, \"disable\", or list of Callback instances (default=None)\n",
      "      Which callbacks to enable. There are three possible values:\n",
      "\n",
      "      If ``callbacks=None``, only use default callbacks,\n",
      "      those returned by ``get_default_callbacks``.\n",
      "\n",
      "      If ``callbacks=\"disable\"``, disable all callbacks, i.e. do not run\n",
      "      any of the callbacks.\n",
      "\n",
      "      If ``callbacks`` is a list of callbacks, use those callbacks in\n",
      "      addition to the default callbacks. Each callback should be an\n",
      "      instance of :class:`.Callback`.\n",
      "\n",
      "      Callback names are inferred from the class\n",
      "      name. Name conflicts are resolved by appending a count suffix\n",
      "      starting with 1, e.g. ``EpochScoring_1``. Alternatively,\n",
      "      a tuple ``(name, callback)`` can be passed, where ``name``\n",
      "      should be unique. Callbacks may or may not be instantiated.\n",
      "      The callback name can be used to set parameters on specific\n",
      "      callbacks (e.g., for the callback with name ``'print_log'``, use\n",
      "      ``net.set_params(callbacks__print_log__keys_ignored=['epoch',\n",
      "      'train_loss'])``).\n",
      "\n",
      "    predict_nonlinearity : callable, None, or 'auto' (default='auto')\n",
      "      The nonlinearity to be applied to the prediction. When set to\n",
      "      'auto', infers the correct nonlinearity based on the criterion\n",
      "      (softmax for :class:`~torch.nn.CrossEntropyLoss` and sigmoid for\n",
      "      :class:`~torch.nn.BCEWithLogitsLoss`). If it cannot be inferred\n",
      "      or if the parameter is None, just use the identity\n",
      "      function. Don't pass a lambda function if you want the net to be\n",
      "      pickleable.\n",
      "\n",
      "      In case a callable is passed, it should accept the output of the\n",
      "      module (the first output if there is more than one), which is a\n",
      "      PyTorch tensor, and return the transformed PyTorch tensor.\n",
      "\n",
      "      This can be useful, e.g., when\n",
      "      :func:`~skorch.NeuralNetClassifier.predict_proba`\n",
      "      should return probabilities but a criterion is used that does\n",
      "      not expect probabilities. In that case, the module can return\n",
      "      whatever is required by the criterion and the\n",
      "      ``predict_nonlinearity`` transforms this output into\n",
      "      probabilities.\n",
      "\n",
      "      The nonlinearity is applied only when calling\n",
      "      :func:`~skorch.classifier.NeuralNetClassifier.predict` or\n",
      "      :func:`~skorch.classifier.NeuralNetClassifier.predict_proba` but\n",
      "      not anywhere else -- notably, the loss is unaffected by this\n",
      "      nonlinearity.\n",
      "\n",
      "    warm_start : bool (default=False)\n",
      "      Whether each fit call should lead to a re-initialization of the\n",
      "      module (cold start) or whether the module should be trained\n",
      "      further (warm start).\n",
      "\n",
      "    verbose : int (default=1)\n",
      "      This parameter controls how much print output is generated by\n",
      "      the net and its callbacks. By setting this value to 0, e.g. the\n",
      "      summary scores at the end of each epoch are no longer printed.\n",
      "      This can be useful when running a hyperparameter search. The\n",
      "      summary scores are always logged in the history attribute,\n",
      "      regardless of the verbose setting.\n",
      "\n",
      "    device : str, torch.device (default='cpu')\n",
      "      The compute device to be used. If set to 'cuda', data in torch\n",
      "      tensors will be pushed to cuda tensors before being sent to the\n",
      "      module. If set to None, then all compute devices will be left\n",
      "      unmodified.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    prefixes_ : list of str\n",
      "      Contains the prefixes to special parameters. E.g., since there\n",
      "      is the ``'module'`` prefix, it is possible to set parameters like\n",
      "      so: ``NeuralNet(..., optimizer__momentum=0.95)``.\n",
      "\n",
      "    cuda_dependent_attributes_ : list of str\n",
      "      Contains a list of all attribute prefixes whose values depend on a\n",
      "      CUDA device. If a ``NeuralNet`` trained with a CUDA-enabled device\n",
      "      is unpickled on a machine without CUDA or with CUDA disabled, the\n",
      "      listed attributes are mapped to CPU.  Expand this list if you\n",
      "      want to add other cuda-dependent attributes.\n",
      "\n",
      "    initialized_ : bool\n",
      "      Whether the :class:`.NeuralNet` was initialized.\n",
      "\n",
      "    module_ : torch module (instance)\n",
      "      The instantiated module.\n",
      "\n",
      "    criterion_ : torch criterion (instance)\n",
      "      The instantiated criterion.\n",
      "\n",
      "    callbacks_ : list of tuples\n",
      "      The complete (i.e. default and other), initialized callbacks, in\n",
      "      a tuple with unique names.\n",
      "\n",
      "    _modules : list of str\n",
      "      List of names of all modules that are torch modules. This list is\n",
      "      collected dynamically when the net is initialized. Typically, there is no\n",
      "      reason for a user to modify this list.\n",
      "\n",
      "    _criteria : list of str\n",
      "      List of names of all criteria that are torch modules. This list is\n",
      "      collected dynamically when the net is initialized. Typically, there is no\n",
      "      reason for a user to modify this list.\n",
      "\n",
      "    _optimizers : list of str\n",
      "      List of names of all optimizers. This list is collected dynamically when\n",
      "      the net is initialized. Typically, there is no reason for a user to modify\n",
      "      this list.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(skorch.NeuralNetRegressor.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instantiate Skorch model\n",
    "net = skorch.NeuralNetRegressor(module = MyNet(n_features = 348,\n",
    "                                               task = 'regression'),\n",
    "                                optimizer = torch.optim.SGD, optimizer__lr = 0.001,\n",
    "                                max_epochs = 20, batch_size = 16, train_split = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split dataset for training, validation, and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, y, test_size = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27820, 348])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1       \u001b[36m62.3015\u001b[0m  47.5030\n",
      "      2       \u001b[36m11.5590\u001b[0m  44.7033\n",
      "      3        \u001b[36m5.6381\u001b[0m  45.6393\n",
      "      4        \u001b[36m3.4205\u001b[0m  46.7653\n",
      "      5        \u001b[36m2.3414\u001b[0m  50.2796\n",
      "      6        \u001b[36m1.7144\u001b[0m  47.3859\n",
      "      7        \u001b[36m1.3254\u001b[0m  49.5965\n",
      "      8        \u001b[36m1.0648\u001b[0m  46.1936\n",
      "      9        \u001b[36m0.8855\u001b[0m  46.1685\n",
      "     10        \u001b[36m0.7521\u001b[0m  44.9505\n",
      "     11        \u001b[36m0.6544\u001b[0m  46.7621\n",
      "     12        \u001b[36m0.5738\u001b[0m  46.5219\n",
      "     13        \u001b[36m0.5123\u001b[0m  47.5097\n",
      "     14        \u001b[36m0.4604\u001b[0m  46.6405\n",
      "     15        \u001b[36m0.4173\u001b[0m  46.0819\n",
      "     16        \u001b[36m0.3808\u001b[0m  46.9239\n",
      "     17        \u001b[36m0.3520\u001b[0m  44.5908\n",
      "     18        \u001b[36m0.3254\u001b[0m  40.1903\n",
      "     19        \u001b[36m0.3028\u001b[0m  48.5742\n",
      "     20        \u001b[36m0.2820\u001b[0m  50.6496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=MyNet(\n",
       "    (layer1): Linear(in_features=348, out_features=696, bias=True)\n",
       "    (layer2): Linear(in_features=696, out_features=1392, bias=True)\n",
       "    (layer3): Linear(in_features=1392, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993076654371598\n"
     ]
    }
   ],
   "source": [
    "### Train Accuracy\n",
    "print(r2_score(y_train, net.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9979037567794474\n"
     ]
    }
   ],
   "source": [
    "### Validation Accuracy\n",
    "print(r2_score(y_val, net.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9982135908127876\n"
     ]
    }
   ],
   "source": [
    "### Test Accuracy\n",
    "print(r2_score(y_test, net.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['optimizer']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net._optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net.set_params(max_epochs = 20)\n",
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
